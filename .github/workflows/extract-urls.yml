name: Extract Player URLs

on:
  # Run on schedule (every 6 hours)
  schedule:
    - cron: '0 */6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
  
  # Run on push to main branch
  push:
    branches:
      - main
    paths:
      - 'script.py'
      - '.github/workflows/*.yml'

jobs:
  extract-urls:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml
      
      - name: Run extractor script
        run: |
          python script.py
        continue-on-error: true
      
      - name: Generate timestamp
        id: timestamp
        run: echo "timestamp=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
      
      - name: Upload JSON results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: player-urls-${{ steps.timestamp.outputs.timestamp }}
          path: player_urls.json
          retention-days: 30
      
      - name: Commit and push results (optional)
        if: success()
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Create results directory if it doesn't exist
          mkdir -p results
          
          # Copy with timestamp
          cp player_urls.json results/player_urls_${{ steps.timestamp.outputs.timestamp }}.json
          cp player_urls.json results/player_urls_latest.json
          
          # Add and commit if there are changes
          git add results/
          git diff --quiet && git diff --staged --quiet || \
            (git commit -m "Update player URLs - ${{ steps.timestamp.outputs.timestamp }}" && git push)
        continue-on-error: true
      
      - name: Create summary
        if: always()
        run: |
          if [ -f player_urls.json ]; then
            echo "## Extraction Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ Script executed successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Extract summary stats using Python
            python << 'EOF' >> $GITHUB_STEP_SUMMARY
          import json
          try:
              with open('player_urls.json', 'r') as f:
                  data = json.load(f)
              
              print(f"**Total Events:** {data.get('total_events', 0)}")
              print("")
              
              if 'events' in data and data['events']:
                  domains = {}
                  for event in data['events']:
                      domain = event.get('player_domain', 'unknown')
                      domains[domain] = domains.get(domain, 0) + 1
                  
                  print("**Player Domains:**")
                  for domain, count in sorted(domains.items(), key=lambda x: x[1], reverse=True):
                      print(f"- {domain}: {count} events")
          except Exception as e:
              print(f"Error reading results: {e}")
          EOF
          else
            echo "## Extraction Failed" >> $GITHUB_STEP_SUMMARY
            echo "❌ Could not generate player_urls.json" >> $GITHUB_STEP_SUMMARY
          fi
